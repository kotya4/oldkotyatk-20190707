<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <!--<meta name="viewport" content="width=device-width,initial-scale=1" />-->
    <link rel="stylesheet" type="text/css" href="css/zaripova.css">
    <title>Zaripova Generator -- kotya.tk</title>
    <script src="src/romanizer.js"></script>
    <script>
      (function(){
        function onload() {
          const ref = document.getElementsByClassName('random-ref');
          const tar = document.getElementById('textarea');
          const cha = document.getElementById('chapter');
          if (ref) {
            const n = (1 + (Math.random() * 4999 | 0));
            for (let r of ref) {
              r.href = '?page=' + n;
            }
          }
          
          const page = parseInt('{{ page }}');
          if (!isNaN(page)) {
            const r = new Romanizer();
            if (page < 10000 && page > 0) {
              cha.innerHTML = 'Глава ' + r.convert(page);
            }
            tar.value = page;
          } else {
            tar.value = 1;
          }
        }
        window.addEventListener('load', onload, false);
      })();
    </script>
  </head>
  <body>
    <div class="header content">
      <img src="img/zaripova-logo.png"></img>
      <form method="get">
        <input class="textarea" type="text" name="page" id="textarea" />
        <input class="button" type="submit" value="Перейти">
      </form>
      <br>
      Powered by <a href="http://kotya.tk">kotya.tk</a>, Oct 2018
      <br><br><br>
      <a class="random-ref">ПЕРЕЙТИ НА СЛУЧАЙНУЮ ГЛАВУ</a>
    </div>
    <div class="text content">
      {% if 'intro' == page %}
        <h2>Введение</h2>
        <h1></h1>
        <p>
          Привет, я -- Случайная Котя. Этот сайт содержит в себе лекции по информатике, сгенерированные компьютером с помощью 
          <a href="https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BF%D1%8C_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0">
          цепей Маркова</a>. Программа, генерирующая текст, изначально была написана на Javascript, но после, для
          миграции на сторону сервера, была переведена на Python 3. Исходный код можно найти на
          <a href="https://github.com/sluchaynayakotya/markov-text-generator">GitHub</a> (быдлокод алерт).
          Чтобы не терять время и сразу же поглядеть на плоды моих трудов, пожалуйста, нажмите <a class="random-ref">сюда</a>,
          и вы перейдете на случайную страницу этой замечательной лекции. Прошу заметить, что сгенерированный текст может содержать в 
          себе повторяющиеся паттерны. Иногда целая глава может состоять только из них, это нормально, т. к. алгоритм никак не
          контроллирует вложенность текста, поэтому некоторые выражения могут ссылаться на самих себя.
          <br><br>
          Благодаря тому, что весь текст генерируется при помощи компьютера, "контент" этого сайта потенциально бесконечен.
          Текст генерируется случайно, однако страницы
          на этом сайте всегда статичны, т. е. перейдя к главе <a href="?page=666">666</a>, вы всегда будете видеть один и тот же
          текст. По моему, это круто, да? На самом деле ничего особенного...<br><br>
          Если вы уже ознакомились с некоторыми главами этих лекций, то, наверное, уже заметили, что для генерации текста 
          используется реально существующий текст. Он был взят из
          свободного доступа, и представляет из себя осмысленный набор выражений. Алгоритм генерации таков, что для создания
          более читабельного и оригинального текста, необходимо использовать такой первоисточник, где объем различных слов минимален,
          тогда как объем выражений, составленных из этих слов, максимален. Для этого идеально подходят рефераты на около-технические
          темы, например, "информатика", "информация", "данные" и т. д. Алгоритм не занимается морфологическим
          анализом текста, и потому генерирующийся текст полностью зависит от слов и выражений в той форме, в которой они были
          из начально представлены в оригинальном тексте (имеется в виду сохранение падежей, склонений, и т. д.) Также при генерации
          использовались "окна" в два слова. Это значит, что текст выглядит более понятным, но в то же время менее оригинальным.
          <br><br>
          Для того, чтобы воспользоваться генератором, можно использовать форму в левом правом углу страницы. Написав номер
          главы, можно попасть на нужную вам страницу. Чтобы попасть на страницу "Введение", на которой вы находитесь сейчас,
          достаточно оставить форму ввода пустой.
          <br><br>
          Далее идет техническое описание. Я считаю нужным предупредить о том, что весь этот текст выглядит так, будто его сгенерировал
          компьютер. На самом деле его написал я. Многие вещи написаны непонятно. То, что я написал дальше, непонятно даже для меня.
          Поэтому, для большей информации смотрите исходный код программы на гитхабе или пишите мне на почту. Почту можно найти
          в исходном коде программы, в тексте лицензии. Также меня можно найти во <a href="https://vk.com/piturd98">Вконтакте</a>.
          <br><br>
          Итак, реализация для JS отличается от реализации для Python тем, что программа на JS способна принимать как
          аргумент обычный текст (см. метод eat(...) в классе Markov файла 'markov-js/markov2.js') и генерировать
          необходимые для генерации текста объекты, такие, как: 1) dic (dictionary) в формате [word, ...] --
          массив из строк, содержащий первое вхождение некоторого слова в тексте (само слово без повторений); 2) tree
          (tree of sequences) в формате [{"seq": [word_index, ...], "next": [{"index": word_index, "weight": weight}, ...],
          "max_weight": max_weight}, ...] -- массив из последовательностей (seq) индексов слов массива dic, массива
          объектов (next), содержащих индекс из dic на следующий за последовательностью слово (next.index), и количество
          вхождений этого слова для данной последовательности (next.weight), и максимальное количетсво вхождений всех
          слов (max_weight) для данной последовательности (т. е. сумма всех вхождений из next). Реализация на Python не
          способна конвертировать обычный текст в нужный тип данных, однако, в отличие от реализации на JS, может загрузить
          эти данные с внешних файлов (см. метод load_from_file(...) класса MarkovChain файла 'markov-py/__init__.py').
          Пример файлов приведен в папке модуля реализации на Python ('markov-py/dictionary.txt' для
          dic и 'markov-py/tree.txt' для tree). Также программа содержит в себе код, генерирующий заголовки. Ее алгоритм не
          имеет отношения к цепям Маркова, и не представляет особого интереса. Грубо говоря, алгоритм реализует случайный
          перебор слов с соответствующими окончаниями по несложной логике, чтобы имитировать псевдо-осмысленные названия для глав.
          Генерация заголовков случайная, и не связана с текстом самих лекций. Оригинальный текст, взятый за основу для генерации,
          достаточно маленький, поэтому генерирующийся текст выглядит слабовато. В какой-то момент я это исправлю, наверное.
          <br><br>
          Это все, что я хотел сказать. Спасибо за внимание.
        </p>
      {% else %}
        <h2 id="chapter">Глава {{ page }}</h2>
        <h1>{{ header }}</h1>
        <p>{{ body }}</p>
      {% end %}
    </div>
  </body>
</html>